{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pandas for high-performance tables\n",
                "\n",
                "- Pandas is the high-powered Python library used for data analysis. \n",
                "  - It is built on top of NumPy and is capable of handling large datasets efficiently. \n",
                "  - Pandas is also used for data visualization as it can plot data in a tabular or graphical form. \n",
                "- It will be the basis of GeoPandas, which we will use to look at vector data\n",
                "  - For now, we will start with an ordinary table of data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Do our imports\n",
                "import pandas\n",
                "import os\n",
                "\n",
                "# Set our file paths (YOU SHOULD HAVE DOWNLOADED THIS FROM GOOGLE DRIVE!)\n",
                "data_directory = '../../../../data'\n",
                "food_prices_filename = 'world_monthly_food_prices.csv'\n",
                "food_prices_path = os.path.join(data_directory, food_prices_filename)\n",
                "\n",
                "# Pandas provides a read_csv function that will read a CSV file into a dataframe\n",
                "food_prices = pandas.read_csv(food_prices_path)\n",
                "\n",
                "# Print the dataframe using default printing options\n",
                "print(food_prices)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Printing the dataframe head()\n",
                "\n",
                "- It's a little hard to take in all the data because it skips rows and columns to make it fit\n",
                "- An alternate way to view it is to use the `head()` method to see the first few rows of the table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print the head of the dataframe. Reminder, the . operator is used to \n",
                "# access a function (technically called method) of an object. \n",
                "# Before I print it, I'm also going to change the default print settings to be wider\n",
                "\n",
                "# Set the display width to 1000\n",
                "pandas.set_option('display.width', 1000)\n",
                "\n",
                "# Print it with the new settings\n",
                "print(food_prices.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explore the different object attributes of the dataframe\n",
                "\n",
                "- For instance look at the column names"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('List of column names:', food_prices.columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Get a specific column\n",
                "- To get a column, use square braces with the name of the column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "food_prices_value_column = food_prices['Value']\n",
                "\n",
                "print('Specific column:', food_prices_value_column)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Specific value in that column:', food_prices_value_column[6])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Iterate through columns\n",
                "\n",
                "- The `food_prices.columns` attribute can be made into a list for iteration\n",
                "- Other (better as we will eventually see) ways to iterate through columns are possible\n",
                "  - Such as itertools\n",
                "- For now, iterate through the columns and sum them up."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The columns attribute is not quite a list. It's a panda's Series and has information about what it indexes\n",
                "print(food_prices.columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# But we can make it into an ordinary list\n",
                "columns_list = list(food_prices.columns)\n",
                "print('columns_list', columns_list)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Iterate through the columns and print the sum\n",
                "for column_name in columns_list:\n",
                "    print('Currently accessing column', column_name)\n",
                "    \n",
                "    current_column = food_prices[column_name]\n",
                "    \n",
                "    # Check the datatype of the current_column\n",
                "    current_data_type = current_column.dtype\n",
                "    print('Datatype of current_column:', current_data_type)\n",
                "    \n",
                "    if current_data_type == 'float64':\n",
                "        print('    Sum of column', column_name, 'is', current_column.sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Under the hood\n",
                "\n",
                "- All parts of the pandas dataframe are represented via numpy arrays\n",
                "  - If you want to access them as numpy arrays instead of Pandas dataframes or columns, you can use the .values attribute"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numpy_array = food_prices_value_column.values\n",
                "print(numpy_array)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Default plotting\n",
                "\n",
                "- By default, pandas has a plot function\n",
                "  - Let's try it"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib\n",
                "from matplotlib import pyplot as plt\n",
                "plt.plot(food_prices['Value'])\n",
                "plt.show() "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Discussion point\n",
                "\n",
                "- Why is the data like this?\n",
                "\n",
                "### Pandas Functionality\n",
                "\n",
                "- Let's start by importing everything afresh and setting a random seed.\n",
                "  - Setting the random seed means we will get the same random numbers each time we run the code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "# Set a seed value for the random generator\n",
                "np.random.seed(48151623)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create an individual column\n",
                "\n",
                "- In pandas, they are called Series\n",
                "- One very important thing to note is that in the output, we see TWO columns\n",
                "  - Pandas always includes an index for every Series or Dataframe \n",
                "  - The index is the leftmost column, and is used to identify each row"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating a Series by passing a list of values, letting pandas create a default integer index:\n",
                "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
                "print(s)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### There are many built-in ways of generating series\n",
                "\n",
                "- For instance, you can automatically generate a series of dates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pandas is very detailed in dealing with dates and all the quirks (leap year?) that this leads to.\n",
                "dates = pd.date_range('20130101', periods=6)\n",
                "print(dates)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Making new dataframes\n",
                "\n",
                "- Dataframes can be made from a a dictionary of series, or from a list of lists, or from a numpy array, or several other possiblities.\n",
                "  - We'll explore a few here\n",
                "  - The primary way is to call the pd.DataFrame() class with specific arguments\n",
                "    - Returns a new dataframe object here named `df`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating a DataFrame by passing a NumPy array, with a datetime index and labeled columns:\n",
                "df_rand = pd.DataFrame(np.random.randn(6, 4), columns=['A', 'B', 'C', 'D'])\n",
                "print('df:\\n', df_rand)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# A mre complex example\n",
                "df2 = pd.DataFrame({'A': 1.,\n",
                "                    'B': pd.Timestamp('20130102'),\n",
                "                    'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
                "                    'D': np.array([3] * 4, dtype='int32'),\n",
                "                    'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
                "                    'F': 'foo'})\n",
                "print(df2.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# In addition to printing the head, there is also a handy .describe() method\n",
                "# this gives descriptive statistics.\n",
                "df2.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### It's numpy matrices all the way down\n",
                "\n",
                "- Dataframes add extra information to make it feel like a table or spreadsheet that we're used to"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Another way you can get back to the the raw array is to_numpy()\n",
                "# (though this might lose a lot of functionality).\n",
                "a = df_rand.to_numpy()\n",
                "print('a\\n', a)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Operations on dataframes: sorting\n",
                "\n",
                "- Here we are going to use the fast sorting algorithm provided by Pandas\n",
                "  - It's called `sort_values()`\n",
                "  - I want to illustrate the most common mistake people make with Pandas and discuss it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We're going to sort by B. But let's print out the B column first.\n",
                "print('B column:\\n', df_rand['B'])\n",
                "\n",
                "# Now let's call the sort_values method on the dataframe.\n",
                "df_rand.sort_values(by='B')\n",
                "\n",
                "# Print it out to compare\n",
                "print('Sorted:\\n', df_rand['B'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Why did it not chamge?\n",
                "\n",
                "- The reason is that `sort_values()` returns a new dataframe, but we didn't assign it to anything.\n",
                "  - We can assign it to a new dataframe, or we can use the `inplace=True` argument to change the dataframe in place."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Easy way to get around this is just to assign the returned dataframe to a variable (even the input variable)\n",
                "df_rand = df_rand.sort_values(by='B')\n",
                "print('Sorted with return:\\n', df_rand)\n",
                "\n",
                "# Alternatively, if you hate returning things, there is the inplace=True command, which will modify the df ... inplace.\n",
                "df_rand.sort_values(by='B', inplace=True)\n",
                "print('Sorted inplace:\\n', df_rand)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Slicing and Dicing\n",
                "\n",
                "- We can slice and dice dataframes in many ways\n",
                "- - We can use the `[]` operator\n",
                "  - We can use the `loc` and `iloc` methods\n",
                "    - loc is for accessing via labels/indices on the data\n",
                "    - iloc is for accessing by position of the data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Slicing with the [] works like numpy\n",
                "\n",
                "# Starts with rows\n",
                "print(df_rand[0:3])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# You can get unintuitive results using the standard \n",
                "# Python / Numpy expressions for selecting and setting are intuitiveits best to use\n",
                "# the optimized pandas data access methods, .at, .iat, .loc and .iloc.\n",
                "\n",
                "## Selecting by LABELS, loc and iloc\n",
                "\n",
                "r = df_rand.loc[0] # 0-th row.\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Discuss difference between df['A'] and df.loc[0]\n",
                "r = df_rand.loc[0, 'A']\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "r = df_rand.loc[:, 'A'] # Colon is a slice, an empty colon means ALL the values.\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SELECTING BY POSITION\n",
                "r = df_rand.iloc[3]\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Selecting with slices\n",
                "r = df_rand.iloc[3:5, 0:2]\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Slices again with an empty slice.\n",
                "r = df_rand.iloc[1:3, :]\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "r = df_rand.iloc[:, 1:3]\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Boolean indexing\n",
                "# Using a single columnâ€™s values to select data.\n",
                "r = df_rand[df_rand['A'] > 0]\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make a copy (why?) and add a column\n",
                "df_copy = df_rand.copy()\n",
                "df_copy['E'] = ['one', 'one', 'two', 'three', 'four', 'three']\n",
                "r = df_copy[df_copy['E'].isin(['two', 'four'])]\n",
                "print(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setting by assigning with a NumPy array:\n",
                "df = df_rand.copy()\n",
                "df.loc[:, 'D'] = np.array([5] * len(df))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Merging and Joining\n",
                "\n",
                "- Merging data is one of the most time-intensive and important data-cleaning skills\n",
                "  - Lets you create \"new\" data by merging other old data!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Join\n",
                "# SQL style merges. See the Database style joining section.\n",
                "\n",
                "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
                "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
                "\n",
                "print(left)\n",
                "print(right)\n",
                "\n",
                "df = pd.merge(left, right, on='key')\n",
                "print('df:\\n', df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Stacking\n",
                "stacked = df.stack()\n",
                "# print('stacked:\\n', stacked)\n",
                "\n",
                "\n",
                "# Pivot Tables\n",
                "df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n",
                "                   'B': ['A', 'B', 'C'] * 4,\n",
                "                   'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
                "                   'D': np.random.randn(12),\n",
                "                   'E': np.random.randn(12)})\n",
                "\n",
                "# print(df) # SPREADSHEET VIEW\n",
                "df = pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])\n",
                "# print(df) # Multiindexed (Pivot table) view.\n",
                "\n",
                "# NOTICE that a pivot table is just the above date but where specific things have been made into multi-level\n",
                "# indices.\n",
                "\n",
                "# PLOTTING\n",
                "ts = pd.Series(np.random.randn(1000),\n",
                "            index=pd.date_range('1/1/2000', periods=1000))\n",
                "\n",
                "ts = ts.cumsum()\n",
                "ts.plot()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Writing to files\n",
                "\n",
                "df.to_csv('foo.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Appendix: Additional tasks with Pandas\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Missing data\n",
                "\n",
                "# First we're going to create a new df by \"reindexing\" the old one, which will shuffle the data into a new\n",
                "# order according to the index provided. At the same time, we're going to add on a new, empty column\n",
                "# EE, which we set as 1 for the first two obs.\n",
                "\n",
                "df1 = df.reindex(index=[2, 0, 1, 3], columns=list(df.columns) + ['EE'])\n",
                "df1.loc[0:1, 'EE'] = 1\n",
                "print(df1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply: Similar to R. Applies a function across many cells (fast because it's vectorized)\n",
                "df.apply(np.cumsum)\n",
                "df.apply(lambda x: x.max() - x.min())\n",
                "print(df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Concat\n",
                "s = pd.Series(range(0, 6))\n",
                "# print('s', s)\n",
                "\n",
                "r = pd.concat([df, s]) # Concatenate it, default is by row, which just puts it on the bottom.\n",
                "\n",
                "r = pd.concat([df, s], axis=1) # Concatenate as a new column\n",
                "\n",
                "# print(r) # Result when concatenating a series of the same size.\n",
                "\n",
                "s = pd.Series(range(0, 7))\n",
                "r = pd.concat([df, s], axis=1) # Concatenate as a new column\n",
                "\n",
                "s = pd.Series(range(0, 2))\n",
                "r = pd.concat([df, s], axis=1) # Concatenate as a new column"
            ]
        }
    ],
    "metadata": [
        {
            "kernelspec": {
                "display_name": "Python 3 (ipykernel)",
                "language": "python",
                "name": "python3"
            }
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 4
}
