{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Automatic feature selection with LASSO regression\n",
                "\n",
                "In this notebook we will learn how LASSO (Least Absolute Shrinkage and Selection Operator) regression works and how it can assist in automatically selecting which variables should be included using a **Cross-Validation** perspective.\n",
                "\n",
                "### Start by importing packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "from sklearn.datasets import load_diabetes\n",
                "from sklearn.feature_selection import SelectFromModel\n",
                "from sklearn import datasets, linear_model\n",
                "from sklearn.linear_model import LassoCV, Lasso\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n",
                "import statsmodels\n",
                "from statsmodels.api import OLS"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Load dataset and inspect it\n",
                "\n",
                "-   Again we're going to use our diabetes dataset.\n",
                "    -   Inspect it again just to remind yourself what is in it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the diabetes dataset\n",
                "diabetes = load_diabetes()\n",
                "\n",
                "# Extract numpy arrays for X and y\n",
                "X = diabetes.data\n",
                "y = diabetes.target\n",
                "\n",
                "# Get the feature names\n",
                "feature_names = diabetes.feature_names\n",
                "\n",
                "# Print them out to look at them\n",
                "print(diabetes['DESCR'])\n",
                "print(feature_names)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Select subset of data\n",
                "\n",
                "-   To speed up calculation, we're going to just use the first 150 observations\n",
                "    -   Use numpy slice notation to grab them out of the X, y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remember the notation for slices: X[start:stop:step]\n",
                "# where omitted values default to start=0, stop=size of dimension, step=1\n",
                "# So, X[:150] means \"grab the first 150 rows\"\n",
                "# X = X[:]\n",
                "# y = y[:150]\n",
                "\n",
                "# Split the data into training/testing sets using scikit-learn's train_test_split() function\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Split the data into training/testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run OLS first (for comparison)\n",
                "\n",
                "Remember the standard Sklearn model steps:\n",
                "\n",
                "1.  create the model object\n",
                "2.  call the object's fit method.\n",
                "3.  use the fitted model to predict something.\n",
                "4.  assess the predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create linear regression object\n",
                "model_ols = linear_model.LinearRegression()\n",
                "\n",
                "# Train the model using the training sets\n",
                "model_ols.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions using the testing set\n",
                "y_train_hat = model_ols.predict(X_train)\n",
                "\n",
                "# The coefficients\n",
                "print(\"Coefficients: \\n\", model_ols.coef_)\n",
                "\n",
                "# The mean squared error\n",
                "mse_ols = mean_squared_error(y_train, y_train_hat)\n",
                "print(\"Mean squared error:\", mse_ols)\n",
                "\n",
                "# The coefficient of determination: 1 is perfect prediction\n",
                "r2_train_ols = r2_score(y_train, y_train_hat)\n",
                "print(\"Coefficient of determination:\", r2_train_ols)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Do it again in the econometrics style\n",
                "\n",
                "-   Recall that the package statsmodels is closer to the econometrician's way of doing things.\n",
                "-   We're going to quickly repeat the steps above but with Statsmodels so we can view it in a nice table form."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train_with_constant = statsmodels.api.add_constant(X_train)\n",
                "result = OLS(y_train, x_train_with_constant).fit().summary()\n",
                "\n",
                "print(result)\n",
                "\n",
                "# Notice that the R-squared is the same as above"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Plot y and y_hat\n",
                "\n",
                "-   Let's also plot y and y_hat compared to one of the most important variables, BMI.\n",
                "    -   We'll see both y and y_hat resemble each other."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot outputs (comparing 1 variable (BMI in column 3) to y and y_hat\n",
                "# plt.scatter() takes 2 numpy arrays.\n",
                "# The X[:, 3] notation gets all rows but only in column at index 3 (BMI)\n",
                "# And recall that y is \"a quantitative measure of disease progression one year after baseline\"\n",
                "\n",
                "# Plot the actual y values in black\n",
                "plt.scatter(X_train[:, 3], y_train, color=\"black\")\n",
                "\n",
                "# Plot the predicted y values in blue\n",
                "plt.scatter(X_train[:, 3], y_train_hat, color=\"blue\")\n",
                "\n",
                "# Add vertical axis label\n",
                "plt.ylabel('Disease progression')\n",
                "\n",
                "# Add horizontal axis label\n",
                "plt.xlabel('BMI')\n",
                "\n",
                "# DISCUSSION QUESTION: Why is BMI centered on 0? Isn't it like a value of 20-30?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Switch to LASSO\n",
                "\n",
                "Now that we've spent all this time setting up our python environment and getting sklearn, it's almost a trivial step in many cases to try out the latest-and-greatest model.\n",
                "\n",
                "### Create a LASSO model object\n",
                "\n",
                "-   Today's goal, however, is to do Lasso on this same dataset.\n",
                "    -   To start, lets create a Lasso object.\n",
                "    -   Notice that we are not setting the alpha/gamma value when we create it.\n",
                "-   STEP 1: Create the object"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create an empty Lasso object with a few initial parameters set\n",
                "model_lasso = Lasso(alpha=1.0, random_state=42, max_iter=10000) # Note, alpha is set by default to 1.0 so we could have omitted it here (though I kept it in to make it clear)\n",
                "print(model_lasso)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Fit the LASSO\n",
                "\n",
                "-   STEP 2: Call the lasso.fit() method.\n",
                "    -   The key think is to understand which X and y you are working with\n",
                "    -   We haven't split into training and testing YET, so it doesn't matter here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_train_hat_lasso = model_lasso.fit(X_train, y_train)\n",
                "print(model_lasso, ': I might look the same but now i\\'m FIT!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Predict with the LASSO\n",
                "\n",
                "-   STEP 3: Predict\n",
                "    -   Save the results to a new variable called y_hat_lasso\n",
                "        -   We will use this later"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_train_hat_lasso = model_lasso.predict(X_train)\n",
                "print('y_hat_lasso', y_train_hat_lasso)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Plot it too to compare it with the OLS plot from above\n",
                "\n",
                "What do you see. Is this expected?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot outputs\n",
                "plt.scatter(X_train[:, 3], y_train, color=\"black\")\n",
                "plt.scatter(X_train[:, 3], y_train_hat_lasso, color=\"blue\")\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Compare the actual coefficients created\n",
                "\n",
                "Class question: How are they different? And how are they similar?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(model_lasso.coef_)\n",
                "print(model_ols.coef_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 1\n",
                "\n",
                "Use a loop to identify the best value of alpha, as measured by r-squared.\n",
                "\n",
                "Write all of the alphas and associated r2 into a dictionary\n",
                "\n",
                "Discussion question for once you're done: what was the optimal alpha and why does this make sense? How does this compare to OLS? Why is it that way?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1 Code\n",
                "scores = {}\n",
                "alphas = np.logspace(-5, -0.05, 30)\n",
                "for alpha in alphas:\n",
                "    model_lasso = Lasso(alpha=alpha, random_state=0, max_iter=10000)\n",
                "    model_lasso.fit(X_train, y_train)\n",
                "    y_train_hat_lasso = model_lasso.predict(X_train)\n",
                "    r2 = r2_score(y_train, y_train_hat_lasso)\n",
                "    scores[alpha] = r2\n",
                "    print('Alpha', alpha, 'r2', r2)\n",
                "\n",
                "# Quick way to get the value from the highest-valued dictionary entry\n",
                "best_alpha = max(scores, key=scores.get)\n",
                "\n",
                "# print best_alpha with all the significant digits\n",
                "print('best_alpha', best_alpha)\n",
                "\n",
                "# This is not very pretty. There MUST be a better way to do this.\n",
                "# There is!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Operationalizing CV with GridSearch\n",
                "\n",
                "-   It seems a little weird to be automatically finding the best model.\n",
                "\n",
                "    -   If we were just applying this to the dataset a single time, this would indeed be p-hacking to the extreme.\n",
                "\n",
                "    -   However, showing its performance on UNSEEN data is quite the opposite of p-hacking.\n",
                "\n",
                "-   Scikit Learn lets us operationalize our method for finding the best model by using GridSearch.\n",
                "\n",
                "-   GridSEarch will search for the best set of \"hyperparameters\" we can find.\n",
                "\n",
                "    -   Here we only have 1 hyperparameter, alpha.\n",
                "\n",
                "        -   Our plan will be to split the training data into 5 folds, and then test each alpha on each fold, keeping track of which alpha performed best.\n",
                "\n",
                "            -   Why split into folds instead of just testing each alpha on one split of the training data?\n",
                "\n",
                "                -   We can eek-out much more training power by reusing the data lots of times in different splits.\n",
                "\n",
                "![](images/paste-1.png)\n",
                "\n",
                "### Setup the inputs for GridSearchCV\n",
                "\n",
                "-   Define a range of alphas we will test using numpy logspace:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "alphas = np.logspace(-6, -0.5, 30)\n",
                "print(alphas)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-   We are going to be passing this range of tuning parameters to a GridSearch\n",
                "\n",
                "    -   It .fit() function will test which alpha works best across all of the folds.\n",
                "\n",
                "-   First though, we have to put the alphas into the form the GridSearchCV function Expects, which is a list of dictionaries.\n",
                "\n",
                "    -   More complex models might have lots of different hyperparameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tuning_parameters = [{'alpha': alphas}]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Choose how many folds to use\n",
                "\n",
                "-   Recall that CV works by calculating the fit quality of different folds of the training data.\n",
                "\n",
                "    -   Here we will just use 5 folds. GridSearchCV will automatically implement the folding and testing logic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_folds = 5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Create the lasso_cv object from the lasso object\n",
                "\n",
                "-   Finally, we have all our objects ready to pass to the GridSearchVC function\n",
                "\n",
                "    -   Create a new GridSearchCV object.\n",
                "\n",
                "        -   Notice that we are reusing model_lasso object we created above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_lasso_cv = GridSearchCV(model_lasso, tuning_parameters, cv=n_folds, refit=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Fit the lasso_cv object\n",
                "\n",
                "When we call the model_lasso_cv.fit() method, we will iteratively be calling the Lasso.fit() with different permutations of tuned parameters and then will return the classifier with the best CV fit."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_lasso_cv.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-   Although it was just one line, we just ran a BOATLOAD of Lasso regressions.\n",
                "\n",
                "-   The `model_lasso_cv` object now has a variety of diagnostic metrics, reporting back on different folds within the Cross Validation. Take a look at them below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('model_lasso_cv keys returned:', model_lasso_cv.cv_results_.keys())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Extract results by score\n",
                "\n",
                "Some relevant results are as below, which we'll extract and assign to lists."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scores = model_lasso_cv.cv_results_['mean_test_score']\n",
                "scores_std = model_lasso_cv.cv_results_['std_test_score']\n",
                "\n",
                "print('scores', scores)\n",
                "print('scores_std', scores_std)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 2:\n",
                "\n",
                "With your table, explore the scores and alphas lists we've created. Identify which alpha is the best, based on the MSE score returned. A challenge here is that sklearn gave us the scores as a list rather than a dictionary (as we built above), so you will need to use the list to create the dictionary.\n",
                "\n",
                "One way to consider doing this would be to create a for loop to iterate through a range(len(scores)): object, saving the alphas and scores to a new dictionary, as in the starter code below.\n",
                "\n",
                "Save the optimal alpha as a new variable called chosen_alpha."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 2 Code\n",
                "\n",
                "output_dict = {}\n",
                "for i in range(len(scores)):\n",
                "    output_dict[alphas[i]] = scores[i]\n",
                "    \n",
                "best_alpha = max(output_dict, key=output_dict.get)\n",
                "\n",
                "print('best_alpha', best_alpha)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Plot out the alphas and their scores"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure().set_size_inches(8, 6)\n",
                "plt.semilogx(alphas, scores)\n",
                "# Also add an annotation vertical dotted line indicating the optimal alpha\n",
                "plt.axvline(best_alpha, linestyle='--', color='.5')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Use the built-in attributes to get the best alpha\n",
                "\n",
                "-   Fortunately, the authors provide a useful best_params\\_ attribute."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('best_parameters:', model_lasso_cv.best_params_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-   Extract the best alpha, which we will use later."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "chosen_alpha = model_lasso_cv.best_params_['alpha']\n",
                "print('chosen_alpha', chosen_alpha)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Rerun LASSO with the best alpha\n",
                "\n",
                "-   Now we can rerun a vanilla (no CV) version of Lasso with that specific alpha.\n",
                "\n",
                "    -   This will return, for instance, a `model_lasso_cv_2.coef_` list."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_lasso_cv_2 = Lasso(alpha=chosen_alpha, random_state=0, max_iter=10000).fit(X_train, y_train)\n",
                "\n",
                "print(\"coefficients\", model_lasso_cv_2.coef_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-   Simply looking at the coefficients tells us which are to be included. Question: How will we know just by looking?\n",
                "\n",
                "### Extract the feature names and column indices of the features that Lasso has selected."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "selected_coefficient_labels = []\n",
                "selected_coefficient_indices = []\n",
                "for i in range(len(model_lasso_cv_2.coef_)):\n",
                "    print('Coefficient', feature_names[i], 'was', model_lasso_cv_2.coef_[i])\n",
                "    if abs(model_lasso_cv_2.coef_[i]) > 0:\n",
                "        selected_coefficient_labels.append(feature_names[i])\n",
                "        selected_coefficient_indices.append(i)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This process led us to the following selected_coefficient_labels:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('selected_coefficient_labels', selected_coefficient_labels)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Switch back to slides\n",
                "\n",
                "## Post-LASSO\n",
                "\n",
                "Finally, now that we have our selected labels, we can use them to select the numpy array columns that we want to use for a post-LASSO run."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_selected = X_train[:, selected_coefficient_indices]\n",
                "print('X_train_selected', X_train_selected)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Plug this new x matrix into our statsmodels OLS function and print that out."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the model and fit it using scikit learn linear_model\n",
                "ols_model_selected = linear_model.LinearRegression()\n",
                "ols_model_selected.fit(X_train_selected, y_train)\n",
                "\n",
                "# Make predictions using the testing set\n",
                "y_train_hat = ols_model_selected.predict(X_train_selected)\n",
                "\n",
                "# report the r-sqr\n",
                "r2_train_ols = r2_score(y_train, y_train_hat)\n",
                "print('r2_train_ols', r2_train_ols)"
            ]
        }
    ],
    "metadata": [
        {
            "kernelspec": {
                "display_name": "Python 3 (ipykernel)",
                "language": "python",
                "name": "python3"
            }
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 4
}
